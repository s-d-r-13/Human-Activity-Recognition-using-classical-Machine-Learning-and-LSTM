{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32 #32 LSTM Units\n",
    "\n",
    "# Initiliazing the sequential model1\n",
    "model1 = Sequential()\n",
    "# Configuring the parameters\n",
    "model1.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model1.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model1.add(Dense(n_classes, activation='sigmoid'))\n",
    "model1.summary()\n",
    "\n",
    "# Compiling the model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model1.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_test, y_test), epochs=epochs)\n",
    "\n",
    "#Plot the train and test loss vs number of epochs\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1) \n",
    "score_train = model.evaluate(X_train, y_train, verbose=1) \n",
    "\n",
    "print('\\nValidation accuracy:', score_test[1])\n",
    "print('Train Accuracy:', score_train[1])\n",
    "\n",
    "print('\\nValidation Loss:', score_test[0]) \n",
    "print('Train Loss:', score_train[0])\n",
    "\n",
    "scores = [score_test[1], score_train[1], score_test[0], score_train[0]]\n",
    "results.append(scores)\n",
    "\n",
    "history1=model1.history #Get the history object which stores all the histories of test/train/validation loss/accuracy\n",
    "\n",
    "#Plot train vs test loss\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "#List of epoch numbers\n",
    "x = list(range(1,epochs+1))\n",
    "\n",
    "#Display the model\n",
    "val_loss = history1.history['val_loss'] #Validation Loss\n",
    "loss = history1.history['loss'] #Training Loss\n",
    "plt_dynamic_loss(x, val_loss, loss, ax)\n",
    "\n",
    "#Get the confusion matrix\n",
    "y_pred=model.predict(X_test)\n",
    "cm_df=get_confusion_matrix(y_test, y_pred) #Prepare the confusion matrix by using get_confusion_matrix() defined above.\n",
    "classes=list(cm_df.index) #Class names = Index Names or Column Names in cm_df\n",
    "\n",
    "#Plot a Non-Normalized confusion matrix\n",
    "plot_confusion_matrix(cm_df, classes, normalize=False, title=\"NON-NORMALIZED CONFUSION MATRIX\")\n",
    "\n",
    "#Plot a Normalized confusion matrix\n",
    "plot_confusion_matrix(cm_df, classes, normalize=True, title=\"NORMALIZED CONFUSION MATRIX\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
